{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669ca2c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:14.567359Z",
     "iopub.status.busy": "2024-10-29T20:55:14.566471Z",
     "iopub.status.idle": "2024-10-29T20:55:28.929378Z",
     "shell.execute_reply": "2024-10-29T20:55:28.928543Z"
    },
    "papermill": {
     "duration": 14.372496,
     "end_time": "2024-10-29T20:55:28.931761",
     "exception": false,
     "start_time": "2024-10-29T20:55:14.559265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd7907c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:28.943909Z",
     "iopub.status.busy": "2024-10-29T20:55:28.942898Z",
     "iopub.status.idle": "2024-10-29T20:55:28.948947Z",
     "shell.execute_reply": "2024-10-29T20:55:28.947995Z"
    },
    "papermill": {
     "duration": 0.014041,
     "end_time": "2024-10-29T20:55:28.951037",
     "exception": false,
     "start_time": "2024-10-29T20:55:28.936996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4346e9e",
   "metadata": {
    "papermill": {
     "duration": 0.004555,
     "end_time": "2024-10-29T20:55:28.960524",
     "exception": false,
     "start_time": "2024-10-29T20:55:28.955969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab66dfce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:28.971729Z",
     "iopub.status.busy": "2024-10-29T20:55:28.971359Z",
     "iopub.status.idle": "2024-10-29T20:55:29.008004Z",
     "shell.execute_reply": "2024-10-29T20:55:29.006911Z"
    },
    "papermill": {
     "duration": 0.044804,
     "end_time": "2024-10-29T20:55:29.010025",
     "exception": false,
     "start_time": "2024-10-29T20:55:28.965221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Script: resnet_builder_keras.py\n",
    "Dependency environment: tf_gpu\n",
    "\n",
    "Script for building 3D Resnet models in pure Keras. \n",
    "Code adapted from https://github.com/JihongJu/keras-resnet3d updated for TF2.0\n",
    "'''\n",
    "\n",
    "from __future__ import (\n",
    "    absolute_import,\n",
    "    division,\n",
    "    print_function,\n",
    "    unicode_literals\n",
    ")\n",
    "import six\n",
    "from math import ceil\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Add\n",
    ")\n",
    "\n",
    "from keras.layers import (\n",
    "    Conv3D,\n",
    "    AveragePooling3D,\n",
    "    MaxPooling3D,\n",
    "    Dropout\n",
    ")\n",
    "\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN (non-trainable) -> relu block.\"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS, trainable=False)(input)  # Set trainable to False\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\n",
    "        \"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-3))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> Dropout -> conv3d block.\"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-3))\n",
    "    dropout_rate = conv_params.setdefault(\"dropout_rate\", 0.3)  # Set the dropout rate here\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        dropout = Dropout(rate=dropout_rate)(activation)  # Apply dropout after activation\n",
    "        conv = Conv3D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            padding=padding,\n",
    "            kernel_regularizer=kernel_regularizer\n",
    "        )(dropout)\n",
    "        return conv\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    \"\"\"3D shortcut to match input and residual and merges them with \"sum\".\"\"\"\n",
    "    stride_dim1 = ceil(int(input.shape[DIM1_AXIS]) \\\n",
    "        / float(int(residual.shape[DIM1_AXIS])))\n",
    "    stride_dim2 = ceil(int(input.shape[DIM2_AXIS]) \\\n",
    "        / float(int(residual.shape[DIM2_AXIS])))\n",
    "    stride_dim3 = ceil(int(input.shape[DIM3_AXIS]) \\\n",
    "        / float(int(residual.shape[DIM3_AXIS])))\n",
    "    equal_channels = residual.shape[CHANNEL_AXIS] \\\n",
    "        == input.shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 \\\n",
    "            or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual.shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\", padding=\"valid\",\n",
    "            kernel_regularizer=l2(1e-4)\n",
    "            )(input)\n",
    "    return Add()([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block3d(block_function, filters, kernel_regularizer, repetitions,\n",
    "                      is_first_layer=False):\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            strides = (1, 1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                strides = (2, 2, 2)\n",
    "            input = block_function(filters=filters, strides=strides,\n",
    "                                   kernel_regularizer=kernel_regularizer,\n",
    "                                   is_first_block_of_first_layer=(\n",
    "                                       is_first_layer and i == 0)\n",
    "                                   )(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "                is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n",
    "                           strides=strides, padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=kernel_regularizer\n",
    "                           )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(filters=filters,\n",
    "                                    kernel_size=(3, 3, 3),\n",
    "                                    strides=strides,\n",
    "                                    kernel_regularizer=kernel_regularizer\n",
    "                                    )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
    "        \"\"\"Instantiate a vanilla ResNet3D keras model.\n",
    "        # Arguments\n",
    "            input_shape: Tuple of input shape in the format\n",
    "            (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='\n",
    "            (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n",
    "            num_outputs: The number of outputs at the final softmax layer\n",
    "            block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n",
    "            repetitions: Repetitions of unit blocks\n",
    "        # Returns\n",
    "            model: a 3D ResNet model that takes a 5D tensor (volumetric images\n",
    "            in batch) as input and returns a 1D vector (prediction) as output.\n",
    "        \"\"\"\n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"Input shape should be a tuple \"\n",
    "                             \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                             \"for tensorflow as backend or \"\n",
    "                             \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                             \"for theano as backend\")\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        \n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(filters=64, kernel_size=(7, 7, 7),\n",
    "                                strides=(2, 2, 2),\n",
    "                                kernel_regularizer=l2(reg_factor)\n",
    "                                )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 1, 1),\n",
    "                             padding=\"same\")(conv1)\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block3d(block_fn, filters=filters,\n",
    "                                      kernel_regularizer=l2(reg_factor),\n",
    "                                      repetitions=r, is_first_layer=(i == 0)\n",
    "                                      )(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average poll and classification\n",
    "        pool2 = AveragePooling3D(pool_size=(block.shape[DIM1_AXIS],\n",
    "                                            block.shape[DIM2_AXIS],\n",
    "                                            block.shape[DIM3_AXIS]),\n",
    "                                 strides=(1, 1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        \n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"softmax\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "        else:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"sigmoid\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs, reg_factor=2e-4):\n",
    "        \"\"\"Build resnet 18.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
    "                                     [2, 2, 2, 2], reg_factor=reg_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ccb2f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:29.023197Z",
     "iopub.status.busy": "2024-10-29T20:55:29.022495Z",
     "iopub.status.idle": "2024-10-29T20:55:29.030287Z",
     "shell.execute_reply": "2024-10-29T20:55:29.029504Z"
    },
    "papermill": {
     "duration": 0.017108,
     "end_time": "2024-10-29T20:55:29.032211",
     "exception": false,
     "start_time": "2024-10-29T20:55:29.015103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def resnet18_(pixel=56, num_outputs=2):\n",
    "    \n",
    "    # Instantiate the models for each branch\n",
    "    optical_flow_model = Resnet3DBuilder.build_resnet_18(input_shape=(37, pixel, pixel, 2), num_outputs=num_outputs)\n",
    "    #optical_flow_model.summary()\n",
    "    \n",
    "    image_model = Resnet3DBuilder.build_resnet_18(input_shape=(38, pixel, pixel, 1), num_outputs=num_outputs)\n",
    "    #image_model.summary()\n",
    "    \n",
    "    # Create input layers\n",
    "    optical_flow_input = optical_flow_model.input\n",
    "    image_input = image_model.input\n",
    "    \n",
    "    # Assuming you want to remove the last layer and use the penultimate layer's output\n",
    "    optical_flow_output = optical_flow_model.layers[-2].output\n",
    "    image_output = image_model.layers[-2].output\n",
    "    \n",
    "    # Concatenate the outputs of the two branches\n",
    "    combined = concatenate([image_output, optical_flow_output])\n",
    "    \n",
    "    # Define the logits layer explicitly\n",
    "    logits = Dense(num_outputs, activation=None, name='logits')(combined)\n",
    "    \n",
    "    # Add activation to the logits for final predictions\n",
    "    predictions = tf.keras.layers.Activation('sigmoid' if num_outputs == 1 else 'softmax', name='predictions')(logits)\n",
    "    model = Model(inputs=[image_input, optical_flow_input], outputs=predictions)\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff99c6",
   "metadata": {
    "papermill": {
     "duration": 0.004511,
     "end_time": "2024-10-29T20:55:29.041432",
     "exception": false,
     "start_time": "2024-10-29T20:55:29.036921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d7fc0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:29.053743Z",
     "iopub.status.busy": "2024-10-29T20:55:29.053333Z",
     "iopub.status.idle": "2024-10-29T20:55:29.065775Z",
     "shell.execute_reply": "2024-10-29T20:55:29.064837Z"
    },
    "papermill": {
     "duration": 0.021536,
     "end_time": "2024-10-29T20:55:29.067724",
     "exception": false,
     "start_time": "2024-10-29T20:55:29.046188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_for_fold(weights_path, model, num_outputs=2):\n",
    "\n",
    "    \"\"\"\n",
    "    Load and return a model with freshly initialized fully connected layers for each fold.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - weights_path: Path to the weights file for the fold.\n",
    "    - model: The base model without the final fully connected layers.\n",
    "    - num_outputs: Number of output classes.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - conv_model: Model with newly initialized fully connected layers and loaded weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_output = model.layers[-3].output  # Output from the layer before the FC layer\n",
    "    logits = Dense(num_outputs, activation=None, name='logits_new')(base_output)\n",
    "    predictions = Activation('sigmoid' if num_outputs == 1 else 'softmax', name='predictions_new')(logits)\n",
    "    conv_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "    conv_model.load_weights(weights_path)\n",
    "\n",
    "    conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return conv_model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_fold_model(conv_model, X_test, y_test, fold_idx):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Evaluate the model for a specific fold, compute metrics (including confusion matrix, ROC AUC, PR AUC), \n",
    "    plot ROC and PR curves, and save predicted probabilities in a .txt file.\n",
    "\n",
    "    Parameters:\n",
    "    - conv_model: The model to be evaluated.\n",
    "    - X_test: Test features (which could include optical flow or not).\n",
    "    - y_test: True labels (one-hot encoded).\n",
    "    - fold_idx: Index of the fold being evaluated (for saving the output).\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    - metrics_dict: Dictionary of accuracy, loss, ROC AUC, PR AUC.\n",
    "    - y_pred_probs: Predicted probabilities for the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle cases where no optical flow data is provided\n",
    "\n",
    "    if X_test[1] is None:\n",
    "        X_test = X_test[0]  # Only use the main test data if optical flow is not provided\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = conv_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_probs = conv_model.predict(X_test, verbose=0)\n",
    "\n",
    "    # Convert probabilities to predicted class indices\n",
    "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    # Compute ROC AUC and PR AUC with class 1 probabilities\n",
    "    prob_class_1 = y_pred_probs[:, 1]\n",
    "\n",
    "\n",
    "    # ROC Curve and AUC computation\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_classes, prob_class_1)\n",
    "    #print(\"fpr\", fpr)\n",
    "    #print(\"tpr\", tpr)\n",
    "    #print(\"roc_thresholds\",roc_thresholds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Precision-Recall Curve and AUC computation\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_true_classes, prob_class_1)\n",
    "    #print(\"precision\", precision)\n",
    "    #print(\"recall\", recall)\n",
    "    #print(\"pr_thresholds\",pr_thresholds)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    return loss, accuracy, roc_auc, pr_auc, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28605d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:29.078939Z",
     "iopub.status.busy": "2024-10-29T20:55:29.078647Z",
     "iopub.status.idle": "2024-10-29T20:55:30.539043Z",
     "shell.execute_reply": "2024-10-29T20:55:30.537939Z"
    },
    "papermill": {
     "duration": 1.468757,
     "end_time": "2024-10-29T20:55:30.541353",
     "exception": false,
     "start_time": "2024-10-29T20:55:29.072596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_fold_data(fold_dir, k_fold):\n",
    "\n",
    "    \"\"\"\n",
    "    Load the training and validation data for a specific fold.\n",
    "    Parameters:\n",
    "    \n",
    "    - fold_dir: Directory where the fold's data is stored.\n",
    "    - k_fold: The fold number to load the data from.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_fold, X_val_fold: Training and validation image data.\n",
    "    - y_train_fold, y_val_fold: Training and validation label data.\n",
    "    - optical_flow_train_fold, optical_flow_val_fold: Optical flow data for training and validation.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train_fold = np.load(os.path.join(fold_dir, f\"fold_{k_fold}/train_videos.npy\"))\n",
    "    X_val_fold = np.load(os.path.join(fold_dir, f\"fold_{k_fold}/test_videos.npy\"))\n",
    "    y_train_fold = np.load(os.path.join(fold_dir, f\"fold_{k_fold}/train_labels.npy\"))\n",
    "    y_val_fold = np.load(os.path.join(fold_dir, f\"fold_{k_fold}/test_labels.npy\"))\n",
    "    optical_flow_train_fold = np.load(os.path.join(fold_dir, f\"fold_{k_fold}/train_optical_flow.npy\"))\n",
    "    optical_flow_val_fold = np.load(os.path.join(fold_dir, f\"fold_{k_fold}/test_optical_flow.npy\"))\n",
    "\n",
    "    return X_train_fold, X_val_fold, y_train_fold, y_val_fold, optical_flow_train_fold, optical_flow_val_fold\n",
    "\n",
    "\n",
    "def run_kfold_evaluation(weights_base_path, dropout_fcc, dropout_cnn, l1_reg, \n",
    "                         fold_dir = '/kaggle/input/13102024-5fold-splits-cross-validation/split_folds', model=resnet18_(), num_outputs=2, k=5):\n",
    "\n",
    "    df_results = pd.DataFrame(columns=['data_type','dropout_fcc', 'l1_reg', 'dropout_cnn', 'fold', \n",
    "                                       'loss', 'accuracy', 'roc_auc', 'pr_auc', 'confusion_matrix'])\n",
    "    \n",
    "\n",
    "    for fold_idx in range(1, k + 1):\n",
    "        \n",
    "        print(f\"Evaluating Fold {fold_idx}...\")\n",
    "\n",
    "        path = os.path.join(weights_base_path, f\"Best_fold_{fold_idx}_cp.ckpt.weights.h5\")\n",
    "\n",
    "        conv_model = load_model_for_fold(path, model, num_outputs)\n",
    "\n",
    "        X_train_fold, X_val_fold, y_train_fold, y_val_fold, optical_flow_train_fold, optical_flow_val_fold = load_fold_data(fold_dir, fold_idx)\n",
    "\n",
    "        loss_train, accuracy_train, roc_auc_train, pr_auc_train, conf_matrix_train = evaluate_fold_model(conv_model, [X_train_fold, optical_flow_train_fold], y_train_fold, fold_idx)\n",
    "\n",
    "        loss_val, accuracy_val, roc_auc_val, pr_auc_val, conf_matrix_val = evaluate_fold_model(conv_model, [X_val_fold, optical_flow_val_fold], y_val_fold, fold_idx)\n",
    "        \n",
    "        # Collect training metrics for each fold\n",
    "        new_row_train = pd.DataFrame({\n",
    "            'data_type' : ['train'],\n",
    "            'dropout_fcc': [dropout_fcc],\n",
    "            'l1_reg': [l1_reg],\n",
    "            'dropout_cnn': ['N/A'],\n",
    "            'fold': [fold_idx],\n",
    "            'loss': [loss_train],\n",
    "            'accuracy': [accuracy_train],\n",
    "            'roc_auc': [roc_auc_train],\n",
    "            'pr_auc': [pr_auc_train],\n",
    "            'confusion_matrix':[conf_matrix_train]})\n",
    "        \n",
    "        df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n",
    "\n",
    "        # Collect validation metrics for each fold\n",
    "        new_row_test = pd.DataFrame({\n",
    "            'data_type' : ['test'],\n",
    "            'dropout_fcc': [dropout_fcc],\n",
    "            'l1_reg': [l1_reg],\n",
    "            'dropout_cnn': ['N/A'],\n",
    "            'fold': [fold_idx],\n",
    "            'loss': [loss_val],\n",
    "            'accuracy': [accuracy_val],\n",
    "            'roc_auc': [roc_auc_val],\n",
    "            'pr_auc': [pr_auc_val],\n",
    "            'confusion_matrix':[conf_matrix_val]})\n",
    "\n",
    "        df_results = pd.concat([df_results, new_row_test], ignore_index=True)\n",
    "        \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3513d11a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:30.552750Z",
     "iopub.status.busy": "2024-10-29T20:55:30.552409Z",
     "iopub.status.idle": "2024-10-29T20:55:30.556344Z",
     "shell.execute_reply": "2024-10-29T20:55:30.555620Z"
    },
    "papermill": {
     "duration": 0.011784,
     "end_time": "2024-10-29T20:55:30.558267",
     "exception": false,
     "start_time": "2024-10-29T20:55:30.546483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_results = run_kfold_evaluation(weights_base_path = '/kaggle/input/20102024-5fold-training-npv-loops-0-001-models/training_weights_dropout_0.3_l1_0.001', \n",
    "#                                 dropout_fcc = 0.3, \n",
    "#                                 dropout_cnn = 'N/A', \n",
    "#                                 l1_reg = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ff2666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:30.568889Z",
     "iopub.status.busy": "2024-10-29T20:55:30.568549Z",
     "iopub.status.idle": "2024-10-29T20:55:30.572328Z",
     "shell.execute_reply": "2024-10-29T20:55:30.571606Z"
    },
    "papermill": {
     "duration": 0.011188,
     "end_time": "2024-10-29T20:55:30.574190",
     "exception": false,
     "start_time": "2024-10-29T20:55:30.563002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_results.to_csv('model_results_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61c4cf",
   "metadata": {
    "papermill": {
     "duration": 0.004479,
     "end_time": "2024-10-29T20:55:30.583367",
     "exception": false,
     "start_time": "2024-10-29T20:55:30.578888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a06766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:30.594355Z",
     "iopub.status.busy": "2024-10-29T20:55:30.593666Z",
     "iopub.status.idle": "2024-10-29T20:55:30.600675Z",
     "shell.execute_reply": "2024-10-29T20:55:30.599818Z"
    },
    "papermill": {
     "duration": 0.014605,
     "end_time": "2024-10-29T20:55:30.602614",
     "exception": false,
     "start_time": "2024-10-29T20:55:30.588009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_models_(l1_reg, dropout_fcc ,base_path):\n",
    "    \n",
    "    main_df = pd.DataFrame(columns=['data_type', 'dropout_fcc', 'l1_reg', 'dropout_cnn', 'fold', \n",
    "                                'loss', 'accuracy', 'roc_auc', 'pr_auc', 'confusion_matrix', 'model_type'])\n",
    "    \n",
    "        \n",
    "        \n",
    "    for j in range(len(dropout_fcc)):\n",
    "\n",
    "        print(f'Hyperparams:= l1_ref: {l1_reg}, dropoutfcc: {dropout_fcc[j]}, dropoutcnn: N/A')\n",
    "\n",
    "        model_path = os.path.join(base_path, f'training_weights_dropout_{dropout_fcc[j]}_l1_{l1_reg}')\n",
    "\n",
    "        df_results = run_kfold_evaluation(weights_base_path = model_path, \n",
    "                                          dropout_fcc = dropout_fcc[j], \n",
    "                                          dropout_cnn = 'N/A', \n",
    "                                          l1_reg = l1_reg)\n",
    "\n",
    "        main_df['model_type'] = 'pre-tunning'\n",
    "\n",
    "        main_df = pd.concat([main_df, df_results], ignore_index=True)\n",
    "\n",
    "        print(' ')\n",
    "        \n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f4728f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:30.613288Z",
     "iopub.status.busy": "2024-10-29T20:55:30.612795Z",
     "iopub.status.idle": "2024-10-29T20:55:30.616797Z",
     "shell.execute_reply": "2024-10-29T20:55:30.615973Z"
    },
    "papermill": {
     "duration": 0.011692,
     "end_time": "2024-10-29T20:55:30.619027",
     "exception": false,
     "start_time": "2024-10-29T20:55:30.607335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1_reg = 0.1\n",
    "\n",
    "\n",
    "dropout_fcc = [0.3,0.4,0.5,0.6,0.7,0.8,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "411fb1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T20:55:30.629363Z",
     "iopub.status.busy": "2024-10-29T20:55:30.629072Z",
     "iopub.status.idle": "2024-10-29T21:06:49.494349Z",
     "shell.execute_reply": "2024-10-29T21:06:49.493104Z"
    },
    "papermill": {
     "duration": 678.872693,
     "end_time": "2024-10-29T21:06:49.496343",
     "exception": false,
     "start_time": "2024-10-29T20:55:30.623650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.3, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730235337.938598      68 service.cc:145] XLA service 0x78f2bc132770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730235337.938661      68 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1730235341.782598      68 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/3814762108.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  main_df = pd.concat([main_df, df_results], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.4, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n",
      " \n",
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.5, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n",
      " \n",
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.6, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n",
      " \n",
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.7, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n",
      " \n",
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.8, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n",
      " \n",
      "Hyperparams:= l1_ref: 0.1, dropoutfcc: 0.9, dropoutcnn: N/A\n",
      "Evaluating Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/2174596720.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, new_row_train], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2...\n",
      "Evaluating Fold 3...\n",
      "Evaluating Fold 4...\n",
      "Evaluating Fold 5...\n",
      " \n"
     ]
    }
   ],
   "source": [
    "base_path = f\"/kaggle/input/20102024-5fold-training-npv-loops-0-1-models\"\n",
    "\n",
    "final_df = evaluate_models_(l1_reg, dropout_fcc ,base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c73eb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T21:06:49.514611Z",
     "iopub.status.busy": "2024-10-29T21:06:49.514258Z",
     "iopub.status.idle": "2024-10-29T21:06:49.527379Z",
     "shell.execute_reply": "2024-10-29T21:06:49.526430Z"
    },
    "papermill": {
     "duration": 0.024216,
     "end_time": "2024-10-29T21:06:49.529350",
     "exception": false,
     "start_time": "2024-10-29T21:06:49.505134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('model_final_0.1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5869714,
     "sourceId": 9626494,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5914462,
     "sourceId": 9677677,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 700.971506,
   "end_time": "2024-10-29T21:06:52.805803",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-29T20:55:11.834297",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
